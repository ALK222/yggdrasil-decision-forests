{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example distance\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ydf scikit-learn plotly -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ydf  # Yggdrasil Decision Forests\n",
    "import pandas as pd  # We use Pandas to load small datasets\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an example distance?\n",
    "\n",
    "Decision forest models define an **implicit measure of proximity or similarity between two examples**, referred to as **distance**. The distance represents how two examples are treated similarly in the model. Informally, **two examples are close if they are of the same class and for the same reasons**.\n",
    "\n",
    "This distance is useful for understanding models and their predictions. For example, we can use it for clustering, manifold learning, or simply to look at the training examples that are nearest to a test example. This can help us to understand why the model made its predictions.\n",
    "\n",
    "Keep in mind that a decision forest's distance measure is just one of many reasonable distance metrics on a dataset. One of its many advantages is that allows comparing features on different scales and with different semantics. \n",
    "\n",
    "In this notebook, we will train a model and use its distance to:\n",
    "\n",
    "- Find training examples that are neighbors of a test example and use them to explain the model's predictions.\n",
    "\n",
    "- Map all the examples onto an interactive two-dimensional plot (also known as a 2D manifold) and automatically detect two-dimensional clusters of examples that behave similarly.\n",
    "\n",
    "- Apply hierarchical clustering to explain how the model works as a whole.\n",
    "\n",
    "**The More You Know:** [Leo Breiman](https://en.wikipedia.org/wiki/Leo_Breiman), the author of the [random forest](https://developers.google.com/machine-learning/glossary#random-forest) learning algorithm, [proposed](https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm#prox) a method to measure the *proximity* between two examples using a pre-trained Random Forest (RF) model. He qualifies this method as <i>\"[...] one of the most useful tools in random forests.\"</i>. When using Random Forest models, this is the distance used by YDF.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find closest training examples to a test example\n",
    "\n",
    "Let's download a classification dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"https://raw.githubusercontent.com/google/yggdrasil-decision-forests/main/yggdrasil_decision_forests/test_data/dataset\"\n",
    "train_ds = pd.read_csv(f\"{ds_path}/adult_train.csv\")\n",
    "test_ds = pd.read_csv(f\"{ds_path}/adult_test.csv\")\n",
    "\n",
    "# Print the first 5 training examples\n",
    "train_ds.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train a random forest on this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ydf.RandomForestLearner(label=\"income\").train(train_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to select a example to explain. Let's select the first example of the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_example = test_ds[:1]\n",
    "selected_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this example, the model predicts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(selected_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, the negative class `<=50K` with $1-0.01=99\\%$ probability.\n",
    "\n",
    "Now, we compute the distance between the selected test example and all the training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = model.distance(train_ds, selected_example).squeeze()\n",
    "\n",
    "print(\"distances:\",distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the the five training examples with smallest distance to our chosen example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_train_idxs = np.argsort(distances)[:5]\n",
    "print(\"close_train_idxs:\",close_train_idxs)\n",
    "\n",
    "print(\"Selected test examples:\")\n",
    "train_ds.iloc[close_train_idxs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- For the chosen example, the model predicted class `<=50K`. For the five closes examples, the model had the same prediction.\n",
    "- The closest examples share many features values, such as `education`, `marital status`, `occupation`, `race`, and working between 37 and 40 `hours per week`. This explains well why these examples are close to each other.\n",
    "- The examples' `age`s range between 30 and 40, meaning the model sees this age range as equivalent for those examples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two dimensional projections of the examples\n",
    "\n",
    "Our first use of the proximity is to project the examples on the two dimensional plane. For that, we use [t-SNE](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE # For 2d projections\n",
    "from plotly.offline import iplot # For interactive plots\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairwise distance between all testing examples\n",
    "distances = model.distance(test_ds, test_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 2d projection\n",
    "t_sne = TSNE(\n",
    "    # Number of dimensions to display. 3d is also possible.\n",
    "    n_components=2,\n",
    "    # Control the shape of the projection. Higher values create more\n",
    "    # distinct but also more collapsed clusters. Can be in 5-50.\n",
    "    perplexity=20,\n",
    "    metric=\"precomputed\",\n",
    "    init=\"random\",\n",
    "    verbose=1,\n",
    "    learning_rate=\"auto\").fit_transform(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create an interactive plot with the example features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example_to_html(example):\n",
    "    return \"<br>\".join([f\"<b>{k}:</b> {v}\" for k, v in example.items()])\n",
    "\n",
    "\n",
    "def interactive_plot(dataset, projections):\n",
    "    colors = (dataset[\"income\"] == \">50K\").map(lambda x: [\"red\", \"blue\"][x])\n",
    "    labels = list(dataset.apply(example_to_html, axis=1).values)\n",
    "    args = {\n",
    "        \"data\": [\n",
    "            go.Scatter(\n",
    "                x=projections[:, 0],\n",
    "                y=projections[:, 1],\n",
    "                text=labels,\n",
    "                mode=\"markers\",\n",
    "                marker={\"color\": colors, \"size\": 3},\n",
    "            )\n",
    "        ],\n",
    "        \"layout\": go.Layout(width=500, height=500, template=\"simple_white\"),\n",
    "    }\n",
    "    iplot(args)\n",
    "\n",
    "\n",
    "interactive_plot(test_ds, t_sne)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Move your mouse over the plot to see the values of the examples.\n",
    "\n",
    "The colors represent the labels. We can see clusters of uniform colors (clusters where all the labels are the same), and clusters of mixed colors (clusters where the model has difficulty making good predictions).\n",
    "\n",
    "Can you make sense of those clusters?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster examples\n",
    "\n",
    "We can also cluster examples. [Many methods](https://scikit-learn.org/stable/modules/clustering.html) are available. Let's use `AgglomerativeClustering`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "num_clusters = 6\n",
    "clustering = AgglomerativeClustering(\n",
    "    n_clusters=num_clusters,\n",
    "    metric=\"precomputed\",\n",
    "    linkage=\"average\",\n",
    ").fit(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we print the statistics of the features and one example in each cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "for cluster_idx in range(num_clusters):\n",
    "    selected_examples = test_ds[clustering.labels_ == cluster_idx]\n",
    "    print(f\"Cluster #{cluster_idx} with {len(selected_examples)} examples\")\n",
    "    print(\"=============================\")\n",
    "    IPython.display.display(selected_examples.describe())\n",
    "    IPython.display.display(selected_examples.iloc[:1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
